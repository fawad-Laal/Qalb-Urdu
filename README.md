# QALB Urdu AI - Independent Evaluation Framework

> **Open-Source Testing and Evaluation Framework for Qalb - The State-of-the-Art Urdu Large Language Model**

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-green.svg)](https://www.python.org/downloads/)

## ğŸ“– Overview

This repository contains an **independent applied evaluation** of the [Qalb Urdu AI model](https://huggingface.co/enstazao/Qalb-1.0-8B-Instruct), conducted to assess practical capabilities for everyday usage scenarios. The evaluation covers **320 test cases** across **8 bilingual categories** over **4 iterative assessment rounds**.

### Key Results

| Metric | Score |
|--------|-------|
| **Peak Score (Round 3)** | 79.2/100 |
| **Final Score (Round 4)** | 77.7/100 |
| **Test Cases** | 320 |
| **Categories** | 8 Bilingual |
| **Evaluation Rounds** | 4 |

## ğŸ“‹ Quick Links

| Resource | Link |
|----------|------|
| ğŸ“Š **Evaluation Report (PDF)** | [QALB-Final-Evaluation-04022026.pdf](reports/QALB-Final-Evaluation-04022026.pdf) |
| ğŸ“ **Evaluation Report (Markdown)** | [FINAL_EVALUATION_REPORT.md](reports/FINAL_EVALUATION_REPORT_20260204_081818.md) |
| ğŸ™ **GitHub Repository** | [fawad-Laal/qalb-urdu](https://github.com/fawad-Laal/qalb-urdu) |
| ğŸ¤— **Qalb on Hugging Face** | [enstazao/Qalb-1.0-8B-Instruct](https://huggingface.co/enstazao/Qalb-1.0-8B-Instruct) |
| ğŸ¦™ **Qalb on Ollama** | [enstazao/qalb:8b-instruct-fp16](https://ollama.com/enstazao/qalb:8b-instruct-fp16) |
| ğŸ“„ **arXiv Paper** | [2601.08141](https://arxiv.org/abs/2601.08141) |

---

## ğŸš€ Installation

### Prerequisites

- **Python 3.10+**
- **Ollama** (for running Qalb model locally)
- **~16GB RAM** recommended for 8B parameter model
- **GPU (Optional)**: CUDA-compatible GPU for faster inference

### Step 1: Clone the Repository

```bash
git clone https://github.com/fawad-Laal/qalb-urdu.git
cd qalb-urdu
```

### Step 2: Create Virtual Environment

```bash
# Windows
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Linux/macOS
python -m venv .venv
source .venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Install Ollama & Pull Qalb Model

```bash
# Install Ollama from https://ollama.com/download
# Then pull the Qalb model:
ollama pull enstazao/qalb:8b-instruct-fp16
```

### Step 5: Set Up Environment Variables (For Report Generation)

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here  # Optional: Only for markdown report generation with GPT
```

---

## ğŸ§ª Running the Evaluation Tests

### Quick Start - Run All Tests

```bash
# Make sure Ollama is running with Qalb model
ollama serve  # In a separate terminal

# Run the complete test suite
python scripts/test_runner.py
```

### Test Categories

The evaluation covers 8 categories in both **Urdu Script** and **Roman Urdu**:

| Category | Description | Test Count |
|----------|-------------|------------|
| Question Answering | Factual knowledge and comprehension | 40 |
| Mathematics | Arithmetic and mathematical reasoning | 40 |
| Reasoning | Logical and commonsense reasoning | 40 |
| Translation | Englishâ†”Urdu translation | 40 |
| Summarization | Text summarization tasks | 40 |
| Creative Writing | Poetry, stories, essays | 40 |
| Conversation | Dialogue and chat | 40 |
| Instruction Following | Following complex instructions | 40 |

### Test Output

Results are saved to:
- `data/baseline/combined_results.json` - Full test results
- `data/checkpoints/` - Checkpoint files for resuming interrupted runs

---

## ğŸ“Š Generating Reports

### Generate PDF Academic Report

```bash
python scripts/generate_academic_pdf.py
```

This generates a professional PDF report with:
- Executive summary and key findings
- Charts and visualizations (score evolution, category performance)
- Category-by-category analysis
- Urdu text examples rendered with Amiri font
- 160 annotated examples in appendices

### Generate Markdown Report (Requires OpenAI API)

```bash
python scripts/generate_final_report.py
```

This uses GPT-5-mini to analyze test results and generate a comprehensive markdown report.

---

## ğŸ“ Project Structure

```
qalb-urdu/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ pyproject.toml                      # Project configuration
â”œâ”€â”€ .env                                # Environment variables (create this)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”œâ”€â”€ urdu_script_tests.json     # Urdu script test cases
â”‚   â”‚   â”œâ”€â”€ roman_urdu_tests.json      # Roman Urdu test cases
â”‚   â”‚   â””â”€â”€ combined_results.json      # Test results
â”‚   â”œâ”€â”€ checkpoints/                    # Test run checkpoints
â”‚   â””â”€â”€ evaluation/                     # Evaluation data
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ OVERVIEW.md                     # Qalb model overview
â”‚   â”œâ”€â”€ ARCHITECTURE.md                 # Technical architecture
â”‚   â”œâ”€â”€ BENCHMARKS.md                   # Performance benchmarks
â”‚   â”œâ”€â”€ ROUND_2_ANALYSIS.md            # Round 2 analysis
â”‚   â”œâ”€â”€ ROUND_3_ANALYSIS.md            # Round 3 analysis
â”‚   â””â”€â”€ ROUND_4_ANALYSIS.md            # Round 4 analysis
â”‚
â”œâ”€â”€ fonts/
â”‚   â””â”€â”€ Amiri/                          # Urdu font for PDF generation
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ QALB-Final-Evaluation-04022026.pdf  # Final PDF report
â”‚   â”œâ”€â”€ FINAL_EVALUATION_REPORT_*.md        # Final markdown report
â”‚   â””â”€â”€ archive/                             # Archived old reports
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_runner.py                  # Main test execution script
â”‚   â”œâ”€â”€ generate_final_report.py        # Markdown report generator (GPT)
â”‚   â”œâ”€â”€ generate_academic_pdf.py        # PDF report generator
â”‚   â””â”€â”€ analyze_*.py                    # Analysis scripts
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_cases.py                   # Test case definitions
â”‚   â””â”€â”€ baseline/                       # Baseline test data
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ ollama_example.py               # Ollama usage example
    â””â”€â”€ transformers_example.py         # Transformers usage example
```

---

## ğŸ”§ Customizing Tests

### Adding New Test Cases

Edit `data/baseline/urdu_script_tests.json` or `roman_urdu_tests.json`:

```json
{
  "id": "qa_new_001",
  "category": "question_answering",
  "prompt": "Ù¾Ø§Ú©Ø³ØªØ§Ù† Ú©Ø§ Ù‚ÙˆÙ…ÛŒ Ù¾Ú¾ÙˆÙ„ Ú©ÙˆÙ† Ø³Ø§ ÛÛ’ØŸ",
  "expected_keywords": ["Ú†Ù†Ø¨ÛŒÙ„ÛŒ", "jasmine"],
  "difficulty": "easy"
}
```

### Test Runner Configuration

Key settings in `scripts/test_runner.py`:

```python
MODEL_NAME = "enstazao/qalb:8b-instruct-fp16"  # Model to test
MAX_RETRIES = 3                                  # Retry failed tests
TIMEOUT_SECONDS = 120                            # Per-test timeout
```

---

## ğŸ“ˆ Evaluation Results Summary

### Performance by Round

| Round | Score | Key Changes |
|-------|-------|-------------|
| **Round 1** | 74.4/100 | Baseline with standard keyword matching |
| **Round 2** | 78.3/100 | +3.9 - Improved Urdu-Roman keyword coverage |
| **Round 3** | 79.2/100 | +0.9 - Peak with refined math evaluation |
| **Round 4** | 77.7/100 | -1.5 - Regression from keyword dilution |

### Strengths Identified
- âœ… Translation tasks: ~86% adequacy/fluency
- âœ… Summarization: ~82% on ROUGE-informed evaluations
- âœ… Consistent bilingual performance (Urdu + Roman)

### Areas for Improvement
- âš ï¸ Mathematical reasoning: ~64%
- âš ï¸ Multi-step logical inference
- âš ï¸ Numeric formatting consistency

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-tests`)
3. Commit your changes (`git commit -m 'Add new test cases'`)
4. Push to the branch (`git push origin feature/new-tests`)
5. Open a Pull Request

---

## ğŸ‘¤ Author

**Fawad Hussain Syed**
- ğŸŒ Website: [fawadhs.dev](https://fawadhs.dev)
- ğŸ“§ Email: [fawad@fawadhs.dev](mailto:fawad@fawadhs.dev)
- ğŸ™ GitHub: [@fawad-Laal](https://github.com/fawad-Laal)

---

## ğŸ“œ License

This project is licensed under the **Apache 2.0 License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Qalb Development Team**: Muhammad Taimoor Hassan, Jawad Ahmed, Muhammad Awais
- **Model**: [enstazao/Qalb-1.0-8B-Instruct](https://huggingface.co/enstazao/Qalb-1.0-8B-Instruct)
- **Base Model**: Meta LLaMA 3.1 8B

---

## ğŸ“š Citation

If you use this evaluation framework, please cite:

```bibtex
@misc{qalb-evaluation-2026,
  author = {Syed, Fawad Hussain},
  title = {QALB Urdu AI Independent Evaluation Framework},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/fawad-Laal/qalb-urdu}
}
```

For the Qalb model itself:

```bibtex
@article{qalb2026,
  title={Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers},
  author={Hassan, Muhammad Taimoor and Ahmed, Jawad and Awais, Muhammad},
  journal={arXiv preprint arXiv:2601.08141},
  year={2026}
}
```
